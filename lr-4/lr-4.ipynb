{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №4. Построение рекомендательная системы.\n",
    "\n",
    "### Задание.\n",
    "***\n",
    "**Цель лабораторной работы:** изучение разработки рекомендательных моделей.\n",
    "\n",
    "**Задание:**  \n",
    "1. Выбрать произвольный набор данных (датасет), предназначенный для построения рекомендательных моделей.\n",
    "2. Опираясь на [материалы лекции](https://nbviewer.jupyter.org/github/ugapanyuk/ml_course_2021/blob/main/common/notebooks/recom/recom.ipynb), сформировать рекомендации для одного пользователя (объекта) двумя произвольными способами.\n",
    "3. Сравнить полученные рекомендации (если это возможно, то с применением метрик).\n",
    "\n",
    "### Выполнение.\n",
    "***\n",
    "Задания буду выполнять на [датасете](https://github.com/bhargaviparanjape/clickbait/tree/master/dataset) из статьи \"Stop Clickbait: Detecting and Preventing Clickbaits in Online News Media\".  \n",
    "Датасет состоит из 2х файлов (кликбейт и не кликбейт заголовки). Подготовоим единый DataFrame с этими данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Michigan, Bank Lends Little of Its Bailout ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Four dead, more than a million in U.S. without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Wyoming, Debate Rages Over Elk Feeding Program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bryant and Lakers Return to the N.B.A. Finals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This Baby's Reaction To Hearing About How She ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>When You Binge-Watch \"Making A Murderer\" And T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>Schiphol airliner crash blamed on altimeter fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>Radiohead Release Rejected Bond Theme Song And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>Chernobyl Taking a Toll on Invertebrates Too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>8 Things No One Tells Guys With Body Image Anx...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             header_text\n",
       "0      In Michigan, Bank Lends Little of Its Bailout ...\n",
       "1      Four dead, more than a million in U.S. without...\n",
       "2      In Wyoming, Debate Rages Over Elk Feeding Program\n",
       "3          Bryant and Lakers Return to the N.B.A. Finals\n",
       "4      This Baby's Reaction To Hearing About How She ...\n",
       "...                                                  ...\n",
       "31995  When You Binge-Watch \"Making A Murderer\" And T...\n",
       "31996  Schiphol airliner crash blamed on altimeter fa...\n",
       "31997  Radiohead Release Rejected Bond Theme Song And...\n",
       "31998       Chernobyl Taking a Toll on Invertebrates Too\n",
       "31999  8 Things No One Tells Guys With Body Image Anx...\n",
       "\n",
       "[32000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data_clickbait = pd.read_csv(\"../data/clickbait_data.txt\", sep = \"\\n\\n\", engine=\"python\", names = [\"header_text\"], header = None)\n",
    "data_non_clickbait = pd.read_csv(\"../data/non_clickbait_data.txt\", sep = \"\\n\\n\", engine=\"python\", names = [\"header_text\"], header = None)\n",
    "dataset = data_clickbait.append(data_non_clickbait)\n",
    "dataset = dataset.sample(frac = 1, random_state = 100)\n",
    "dataset = dataset.reset_index(drop = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенизацию и стемминг текстов заголовков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/adminu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "documents = dataset[\"header_text\"].tolist()\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "word_corpus = list()\n",
    "tokenizer = WordPunctTokenizer()\n",
    "stemmer = PorterStemmer()\n",
    "for line in documents:\n",
    "    line = re.sub(\"[^a-z]\",\" \", line.strip().lower()) # Избавляемся от не a-z символов\n",
    "    words = tokenizer.tokenize(line)\n",
    "    words = [stemmer.stem(word) for word in words if not word in stop_words]\n",
    "    word_corpus.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним векторизацию заголовков на основе алгоритма word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.34 s, sys: 77.2 ms, total: 5.42 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%time w2v_model = word2vec.Word2Vec(word_corpus, vector_size = 100, workers = 4, sample=1e-3) #min_count = 10, window=10,\n",
    "word_vectors = w2v_model.wv # Сохраним \"словарь\", полученный в результате обучения: \"слово:вектор\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим рекомендации для такого заголовка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fernando Alonso wins 2010 Singapore Grand Prix\n"
     ]
    }
   ],
   "source": [
    "print(documents[300])\n",
    "target_header_vec = word_vectors[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
